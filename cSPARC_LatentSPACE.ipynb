{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b28366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out the cSPARC .cs file format\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For a non-memory-mapped array\n",
    "data = np.fromfile('./csparc/J6_particles.cs', dtype=float)  # Specify the data type explicitly\n",
    "\n",
    "# Reshape the data to match the type_info structure\n",
    "print(data)\n",
    "print(f\"Data type: {data.dtype}\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    data = np.load('./csparc/J6_particles.cs')\n",
    "    \n",
    "    if isinstance(data, np.ndarray) and data.dtype.names is not None:\n",
    "        print(\"Column Headers:\")\n",
    "        print(data.dtype.names)\n",
    "    else:\n",
    "        print(\"The file does not contain structured array headers.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Print the first few rows\n",
    "print(\"First few rows of data:\")\n",
    "print(data[:5])\n",
    "print(\"Check to see if it is the same particle order as the cryoDRGN\")\n",
    "print(data[65000:65010])\n",
    "\n",
    "print(f\"Data type: {data.dtype}\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "\n",
    "# Extract component values from each mode\n",
    "components_mode0 = data['components_mode_0/value']\n",
    "components_mode1 = data['components_mode_1/value']\n",
    "components_mode2 = data['components_mode_2/value']\n",
    "\n",
    "# Stack the three components along a new axis to form a 3D vector for each row\n",
    "components_vectors = np.stack([components_mode0, components_mode1, components_mode2], axis=1)\n",
    "\n",
    "# test to see if it works\n",
    "print(\"Shape of components_vectors:\", components_vectors.shape)\n",
    "print(\"\\nFirst latent space vectors:\")\n",
    "print(components_vectors[:5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extract_latent_space_vectors(structured_array):\n",
    "    \"\"\"\n",
    "    Extracts component values from different modes and combines them into vectors.\n",
    "    \n",
    "    Parameters:\n",
    "        - structured_array: A structured NumPy array containing component data.\n",
    "        \n",
    "    Returns:\n",
    "        An n-dimensional numpy ndarray where each row is a vector of components from each mode.\n",
    "    \"\"\"\n",
    "    # Identify all columns matching the pattern 'component_mode_X/value'\n",
    "    component_columns = [col for col in structured_array.dtype.names if re.match(r'components_mode_\\d+/value', col)]\n",
    "    \n",
    "    if not component_columns:\n",
    "        raise ValueError(\"No component columns found in the structured array.\")\n",
    "    \n",
    "    # Extract values from each identified column\n",
    "    components = []\n",
    "    for col in component_columns:\n",
    "        # Extract the mode number from the column name\n",
    "        mode_number = int(re.search(r'\\d+', col).group())\n",
    "        # Append the component values to the list\n",
    "        components.append(structured_array[col])\n",
    "    \n",
    "    # Stack the component arrays along a new axis to form vectors\n",
    "    stacked_components = np.stack(components, axis=1)\n",
    "    \n",
    "    return stacked_components\n",
    "\n",
    "# Example usage:\n",
    "# Load your structured array (replace 'your_data.cs' with your actual file path)\n",
    "\n",
    "\n",
    "# Extract components into vectors\n",
    "z = extract_latent_space_vectors(data) \n",
    "print(\"Shape of the resulting array:\", z.shape)\n",
    "print(\"First few vectors:\\n\", z[:5, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking firstly at latent space vector magnitudes.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# this function is the same as np.linalg.norm\n",
    "def calculate_vector_magnitudes(vectors):\n",
    "    \"\"\"\n",
    "    Calculates the magnitudes of vectors extracted from a NumPy array.\n",
    "    \n",
    "    Parameters:\n",
    "        - vectors: A n-D numpy ndarray where each row is a vector.\n",
    "        \n",
    "    Returns:\n",
    "        A 1D numpy ndarray where each element is the magnitude of the corresponding vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the magnitude of each vector\n",
    "    squared = np.square(vectors)\n",
    "    sum_squared = np.sum(squared, axis=1)\n",
    "    magnitudes = np.sqrt(sum_squared)\n",
    "    \n",
    "    return magnitudes\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "mags = calculate_vector_magnitudes(z)\n",
    "print(\"Magnitudes:\", mags[:5])\n",
    "\n",
    "mags2 = np.linalg.norm(z, axis=1)\n",
    "print(\"Magnitudes using np.linalg.norm:\", mags2[:5])\n",
    "\n",
    "\n",
    "\n",
    "# Separate the first 65,000 entries\n",
    "OA = z[:65000]\n",
    "OEA = z[65000:]\n",
    "\n",
    "# Calculate the magnitude of each vector in your dataset\n",
    "OA_magnitudes = calculate_vector_magnitudes(OA)\n",
    "OEA_magnitudes = calculate_vector_magnitudes(OEA)\n",
    "\n",
    "\n",
    "\n",
    "# Plot histograms for both subsets\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(OA_magnitudes, bins=500, alpha=0.5, label='OA')\n",
    "plt.hist(OEA_magnitudes, bins=500, alpha=0.5, label='OEA')\n",
    "#plt.hist(OEA_magnitudes, bins=500,  alpha=0.5,label='OEA', color='orange')   \n",
    "plt.title('Histogram of Vector Magnitudes')\n",
    "plt.xlabel('Magnitude')\n",
    "plt.xlim(0,200)\n",
    "#plt.ylim(0, 6000)\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Boxplot for both subsets\n",
    "plt.subplot(1,2,2)\n",
    "plt.violinplot([OA_magnitudes, OEA_magnitudes], showmeans=True)\n",
    "plt.title('ViolinPlot of Vector Magnitudes')\n",
    "plt.xticks([1, 2], ['OA', 'OEA'])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Perform t-test to compare means of both subsets\n",
    "t_stat, p_value = stats.ttest_ind(OA_magnitudes, OEA_magnitudes)\n",
    "print('T-test')\n",
    "print('T-Statistic:', t_stat)\n",
    "print('P-Value:', p_value)\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(OA_magnitudes, OEA_magnitudes, alternative='two-sided')\n",
    "print('Mann-Whitney U-Test')\n",
    "print('U-Statistic:', u_stat)\n",
    "print('P-Value:', p_value)\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(OA_magnitudes, OEA_magnitudes)\n",
    "print('ANOVA Test')\n",
    "print('F-Statistic:', f_stat)\n",
    "print('P-Value:', p_value)\n",
    "\n",
    "mean_OA = np.mean(OA_magnitudes)\n",
    "mean_OEA = np.mean(OEA_magnitudes)\n",
    "print('Mean OA Magnitude:', mean_OA, 'SD', np.std(OA_magnitudes))\n",
    "print('Mean OEA Magnitude:', mean_OEA, 'SD', np.std(OEA_magnitudes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Create a function to perform UMAP and save the results in a .pkl file\n",
    "def perform_and_save_umap(data, filename):\n",
    "    if filename.exists():\n",
    "        print(\"Loading UMAP embeddings from disk...\")\n",
    "        data_umap = joblib.load(filename)\n",
    "    else:\n",
    "        print(\"Performing UMAP and saving the results to disk...\")\n",
    "        umap_reducer = umap.UMAP(n_components=2, metric='euclidean', min_dist=0.1, n_neighbors=50, spread=1.5, learning_rate=0.5, negative_sample_rate=10, init='pca', random_state=42)\n",
    "        data_umap = umap_reducer.fit_transform(data)\n",
    "        joblib.dump(data_umap, filename)\n",
    "    return data_umap\n",
    "\n",
    "# Define filenames for the UMAP embeddings\n",
    "#filename_OA_subset_A = Path(\"umap_embeddings_OA_subset_A.pkl\")\n",
    "#filename_OA_subset_B = Path(\"umap_embeddings_OA_subset_B.pkl\")\n",
    "#filename_OEA_subset_A = Path(\"umap_embeddings_OEA_subset_A.pkl\")\n",
    "#filename_OEA_subset_B = Path(\"umap_embeddings_OEA_subset_B.pkl\")\n",
    "filename_OA = Path(\"umap_embeddings_OA.pkl\")\n",
    "filename_OEA = Path(\"umap_embeddings_OEA.pkl\")\n",
    "\n",
    "# Perform UMAP on subsets and save the results to disk\n",
    "#data_umap_OA_subset_A = perform_and_save_umap(OA_subset_A, filename_OA_subset_A)\n",
    "#data_umap_OA_subset_B = perform_and_save_umap(OA_subset_B, filename_OA_subset_B)\n",
    "#data_umap_OEA_subset_A = perform_and_save_umap(OEA_subset_A, filename_OEA_subset_A)\n",
    "#data_umap_OEA_subset_B = perform_and_save_umap(OEA_subset_B, filename_OEA_subset_B)\n",
    "data_umap_OA = perform_and_save_umap(OA, filename_OA)\n",
    "data_umap_OEA = perform_and_save_umap(OEA, filename_OEA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a function to perform tSNE and save the results in a .pkl file\n",
    "def perform_and_save_tsne(data, filename, perplexity=100, n_iter=1000):\n",
    "    if filename.exists():\n",
    "        print(\"Loading t-SNE embeddings from disk...\")\n",
    "        data_tsne = joblib.load(filename)\n",
    "    else:\n",
    "        print(\"Performing t-SNE and saving the results to disk...\")\n",
    "        # Convert data from numpy array to tensor\n",
    "        data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "        # Check if GPU is available\n",
    "        if tf.test.is_gpu_available():\n",
    "            print(\"Using GPU for tSNE\")\n",
    "            with tf.device('/GPU:0'):\n",
    "                # Perform tSNE\n",
    "                tsne = TSNE(perplexity=perplexity, n_iter=n_iter, random_state=42)\n",
    "                data_tsne = tsne.fit_transform(data_tensor)\n",
    "        else:\n",
    "            print(\"Using CPU for tSNE\")\n",
    "            # Perform tSNE on CPU\n",
    "            tsne = TSNE(perplexity=perplexity, n_iter=n_iter, random_state=42)\n",
    "            data_tsne = tsne.fit_transform(data)\n",
    "        joblib.dump(data_tsne, filename)\n",
    "    return data_tsne\n",
    "\n",
    "# Define filenames for the t-SNE embeddings\n",
    "filename_OA_subset_A = Path(\"t-sne_embeddings_OA_subset_A.pkl\")\n",
    "filename_OA_subset_B = Path(\"t-sne_embeddings_OA_subset_B.pkl\")\n",
    "filename_OEA_subset_A = Path(\"t-sne_embeddings_OEA_subset_A.pkl\")\n",
    "filename_OEA_subset_B = Path(\"t-sne_embeddings_OEA_subset_B.pkl\")\n",
    "filename_OA = Path(\"t-sne_embeddings_OA.pkl\")\n",
    "filename_OEA = Path(\"t-sne_embeddings_OEA.pkl\")\n",
    "\n",
    "\n",
    "# Perform tSNE on subsets and save the results to disk\n",
    "#data_tsne_OA_subset_A = perform_and_save_tsne(OA_subset_A, filename_OA_subset_A)\n",
    "#data_tsne_OA_subset_B = perform_and_save_tsne(OA_subset_B, filename_OA_subset_B)\n",
    "#data_tsne_OEA_subset_A = perform_and_save_tsne(OEA_subset_A, filename_OEA_subset_A)\n",
    "#data_tsne_OEA_subset_B = perform_and_save_tsne(OEA_subset_B, filename_OEA_subset_B)\n",
    "data_tsne_OA = perform_and_save_tsne(OA, filename_OA)\n",
    "data_tsne_OEA = perform_and_save_tsne(OEA, filename_OEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a425ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)  # We are reducing to 3 dimensions for visualization\n",
    "# Perform PCA on the original data\n",
    "data_pca_OA = pca.fit_transform(OA)\n",
    "data_pca_OEA = pca.fit_transform(OEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3aa472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting UMAP\n",
    "\n",
    "UMAP_OA_magnitudes = np.linalg.norm(data_umap_OA, ord=2, axis=1)\n",
    "UMAP_OEA_magnitudes = np.linalg.norm(data_umap_OEA, ord=2, axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.title('UMAP of latent space OA')   \n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.scatter(data_umap_OA[:,0], data_umap_OA[:,1], alpha=0.9, label='OA',marker=\".\")\n",
    "\n",
    "plt.subplot(3, 2, 2)  # 1 row, 2 columns, second plot\n",
    "plt.hexbin(data_umap_OA[:, 0], data_umap_OA[:, 1], gridsize=50, cmap='Oranges', mincnt=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Counts')\n",
    "plt.title('UMAP Hexbin Visualization of the OA Dataset')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "plt.title('UMAP of latent space OEA')\n",
    "plt.scatter(data_umap_OEA[:,0], data_umap_OEA[:,1], alpha=0.9, label='OEA',marker=\".\")\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "plt.hexbin(data_umap_OEA[:, 0], data_umap_OEA[:, 1], gridsize=50, cmap='Oranges', mincnt=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Counts')\n",
    "plt.title('UMAP Hexbin Visualization of the OEA Dataset')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "plt.scatter(data_umap_OA[:,0], data_umap_OA[:,1], alpha=0.9, label='OA',marker=\".\")\n",
    "plt.scatter(data_umap_OEA[:,0], data_umap_OEA[:,1], alpha=0.1, label='OEA',marker=\".\")\n",
    "plt.title('UMAP of OA and OEA')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "plt.hist(UMAP_OA_magnitudes, bins=100, alpha=0.5, label='OA')\n",
    "plt.hist(UMAP_OEA_magnitudes, bins=100, alpha=0.5, label='OEA')\n",
    "plt.title('Histogram of UMAP Vector Magnitudes')\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f821bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Plots \n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.scatter(data_pca_OA[:,0], data_pca_OA[:,1], alpha=0.9, label='OA',marker=\".\")\n",
    "plt.scatter(data_pca_OEA[:,0], data_pca_OEA[:,1], alpha=0.3, label='OEA',marker=\".\")\n",
    "plt.legend()\n",
    "plt.title('PCA of 1st and 2nd Principal Component')\n",
    "plt.xlabel('Principal Component 0')\n",
    "plt.ylabel('Principal Component 1')\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(data_pca_OA[:,0], data_pca_OA[:,2], alpha=0.9, label='OA',marker=\".\")\n",
    "plt.scatter(data_pca_OEA[:,0], data_pca_OEA[:,2], alpha=0.3, label='OEA',marker=\".\")\n",
    "plt.legend()\n",
    "plt.title('PCA of 1st and 3rd Principal Component')\n",
    "plt.xlabel('Principal Component 0')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.scatter(data_pca_OA[:,1], data_pca_OA[:,2], alpha=0.9, label='OA',marker=\".\")\n",
    "plt.scatter(data_pca_OEA[:,1], data_pca_OEA[:,2], alpha=0.3, label='OEA',marker=\".\")\n",
    "plt.legend()\n",
    "plt.title('PCA of 2nd and 3rd Principal Component')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08466d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiPLOT tSNE \n",
    "\n",
    "plt.figure(figsize=(20, 30))  # Create a figure with size to accommodate two plots\n",
    "\n",
    "# First subplot: Scatter plot for OA \n",
    "plt.subplot(3, 2, 1)  # 1 row, 2 columns, first plot\n",
    "plt.scatter(data_tsne_OA[:, 0], data_tsne_OA[:, 1], alpha=0.3, label='OA', marker=\".\")\n",
    "plt.legend()\n",
    "plt.title('t-SNE Visualization of OA')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "\n",
    "# Second subplot: Hexbin plot for the same data (you can add OEA if needed)\n",
    "plt.subplot(3, 2, 2)  # 1 row, 2 columns, second plot\n",
    "plt.hexbin(data_tsne_OA[:, 0], data_tsne_OA[:, 1], gridsize=40, cmap='Oranges', mincnt=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Counts')\n",
    "plt.title('tSNE Hexbin Visualization of the OA Dataset')\n",
    "plt.xlabel('tSNE Component 1')\n",
    "plt.ylabel('tSNE Component 2')\n",
    "\n",
    "plt.subplot(3, 2, 3)  # 1 row, 2 columns, first plot\n",
    "plt.scatter(data_tsne_OEA[:, 0], data_tsne_OEA[:, 1], alpha=0.3, label='OA', marker=\".\")\n",
    "plt.legend()\n",
    "plt.title('t-SNE Visualization of OEA')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "\n",
    "plt.subplot(3, 2, 4)  # 1 row, 2 columns, second plot\n",
    "plt.hexbin(data_tsne_OEA[:, 0], data_tsne_OEA[:, 1], gridsize=40, cmap='Oranges', mincnt=1)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Counts')\n",
    "plt.title('tSNE Hexbin Visualization of the OEA Dataset')\n",
    "plt.xlabel('tSNE Component 1')\n",
    "plt.ylabel('tSNE Component 2')\n",
    "\n",
    "# Comparison Sublplot\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.scatter(data_tsne_OA[:, 0], data_tsne_OA[:, 1], alpha=0.3, label='OA', marker=\".\")\n",
    "plt.scatter(data_tsne_OEA[:, 0], data_tsne_OEA[:, 1], alpha=0.3, label='OEA', marker=\".\")\n",
    "plt.legend()\n",
    "plt.title('t-SNE Visualization of OA and OEA')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryodrgn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
